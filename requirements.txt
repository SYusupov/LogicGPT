# for inference
llama_cpp_python

# for finetuning and running the LLM model
# torch==2.3.0+cu121 --find-links https://download.pytorch.org/whl/cu121
torch==2.3.0
unsloth==2024.8
fastai==2.7.17
numpy==1.26.4
bitsandbytes==0.43.3
transformers==4.44.2
xformers==0.0.26.post1
peft==0.12.0

# for the application
fastapi
uvicorn==0.30.6
pytest

# for evaluation with llama_cpp and lm-evaluation-harness
lm-eval
sse_starlette
starlette_context
pydantic_settings